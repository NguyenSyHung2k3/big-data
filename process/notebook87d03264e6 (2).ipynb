{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-26T03:36:24.281117Z",
     "iopub.status.busy": "2024-12-26T03:36:24.280607Z",
     "iopub.status.idle": "2024-12-26T03:36:32.645418Z",
     "shell.execute_reply": "2024-12-26T03:36:32.644156Z",
     "shell.execute_reply.started": "2024-12-26T03:36:24.281073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T03:36:32.647413Z",
     "iopub.status.busy": "2024-12-26T03:36:32.647026Z",
     "iopub.status.idle": "2024-12-26T03:36:37.128587Z",
     "shell.execute_reply": "2024-12-26T03:36:37.127229Z",
     "shell.execute_reply.started": "2024-12-26T03:36:32.647386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T03:36:37.131088Z",
     "iopub.status.busy": "2024-12-26T03:36:37.130730Z",
     "iopub.status.idle": "2024-12-26T03:36:37.228383Z",
     "shell.execute_reply": "2024-12-26T03:36:37.227212Z",
     "shell.execute_reply.started": "2024-12-26T03:36:37.131056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import csv\n",
    "import ijson\n",
    "import uuid\n",
    "from pyspark.sql import SparkSession\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T03:37:18.769526Z",
     "iopub.status.busy": "2024-12-26T03:37:18.769150Z",
     "iopub.status.idle": "2024-12-26T03:46:37.195964Z",
     "shell.execute_reply": "2024-12-26T03:46:37.194754Z",
     "shell.execute_reply.started": "2024-12-26T03:37:18.769489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ijson\n",
    "import json\n",
    "import uuid\n",
    "import random\n",
    "from decimal import Decimal\n",
    "\n",
    "# Path to the input and output JSON files\n",
    "input_file = \"after_merged.json\"\n",
    "output_file = \"expanded.json\"\n",
    "\n",
    "# Function to add noise to numerical values\n",
    "def add_noise(value, scale=0.1, min_value=0, max_value=100):\n",
    "    if isinstance(value, (int, float)):\n",
    "        noise = random.uniform(-scale, scale) * value\n",
    "        noisy_value = value + noise\n",
    "        # Clamp the value within the specified range\n",
    "        return max(min_value, min(max_value, round(noisy_value, 6)))\n",
    "    return value\n",
    "\n",
    "# Function to generate a new record with (Remix)\n",
    "def generate_remix_record(record):\n",
    "    new_record = record.copy()\n",
    "    new_record[\"Track ID\"] = str(uuid.uuid4())  # Generate a new Track ID\n",
    "    new_record[\"Track Name\"] = f\"{record['Track Name']} (Remix)\"  # Add (Remix)\n",
    "    new_record[\"Popularity\"] = add_noise(record[\"Popularity\"], scale=10, min_value=0, max_value=100)\n",
    "    new_record[\"Energy\"] = add_noise(record[\"Energy\"], scale=0.05)\n",
    "    new_record[\"Tempo\"] = add_noise(record[\"Tempo\"], scale=2)\n",
    "    return new_record\n",
    "\n",
    "# Function to generate a new record with (Lofi)\n",
    "def generate_lofi_record(record):\n",
    "    new_record = record.copy()\n",
    "    new_record[\"Track ID\"] = str(uuid.uuid4())  # Generate a new Track ID\n",
    "    new_record[\"Track Name\"] = f\"{record['Track Name']} (Lofi)\"  # Add (Lofi)\n",
    "    new_record[\"Popularity\"] = add_noise(record[\"Popularity\"], scale=5, min_value=0, max_value=100)\n",
    "    new_record[\"Energy\"] = add_noise(record[\"Energy\"], scale=0.03)\n",
    "    new_record[\"Tempo\"] = add_noise(record[\"Tempo\"], scale=1.5)\n",
    "    return new_record\n",
    "\n",
    "# Custom JSON encoder to handle Decimal objects\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, Decimal):\n",
    "            return float(obj)  # Convert Decimal to float\n",
    "        return super().default(obj)\n",
    "\n",
    "# Process the JSON file using ijson\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    # Start the JSON array\n",
    "    outfile.write(\"[\\n\")\n",
    "    items = ijson.items(infile, \"item\")\n",
    "    first = True  # Track if it's the first item\n",
    "\n",
    "    for item in items:\n",
    "        # Write the original record\n",
    "        if not first:\n",
    "            outfile.write(\",\\n\")\n",
    "        json.dump(item, outfile, indent=4, ensure_ascii=False, cls=CustomJSONEncoder)\n",
    "\n",
    "        # Write the new (Remix) record\n",
    "        outfile.write(\",\\n\")\n",
    "        remix_record = generate_remix_record(item)\n",
    "        json.dump(remix_record, outfile, indent=4, ensure_ascii=False, cls=CustomJSONEncoder)\n",
    "\n",
    "        # Check if the original Track Name doesn't contain (Remix) and add (Lofi)\n",
    "        if \"(Remix)\" not in item[\"Track Name\"]:\n",
    "            outfile.write(\",\\n\")\n",
    "            lofi_record = generate_lofi_record(item)\n",
    "            json.dump(lofi_record, outfile, indent=4, ensure_ascii=False, cls=CustomJSONEncoder)\n",
    "\n",
    "        first = False\n",
    "\n",
    "    # End the JSON array\n",
    "    outfile.write(\"\\n]\")\n",
    "\n",
    "print(f\"Expanded data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T03:48:24.761457Z",
     "iopub.status.busy": "2024-12-26T03:48:24.761032Z",
     "iopub.status.idle": "2024-12-26T03:48:24.771447Z",
     "shell.execute_reply": "2024-12-26T03:48:24.770181Z",
     "shell.execute_reply.started": "2024-12-26T03:48:24.761429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path  = \"expanded.json\"  \n",
    "\n",
    "def extract_keys(obj, prefix=\"\"):\n",
    "    keys = []\n",
    "    for key, value in obj.items():\n",
    "        full_key = f\"{prefix}.{key}\" if prefix else key\n",
    "        if isinstance(value, dict):\n",
    "            keys.extend(extract_keys(value, prefix=full_key))\n",
    "        else:\n",
    "            keys.append(full_key)\n",
    "    return keys\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    items = ijson.items(file, \"item\")\n",
    "    first_item = next(items, None)\n",
    "    \n",
    "    if first_item:\n",
    "        columns = extract_keys(first_item)\n",
    "        print(\"Columns:\", columns)\n",
    "    else:\n",
    "        print(\"The JSON file is empty or not structured as an array of objects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T03:49:08.857357Z",
     "iopub.status.busy": "2024-12-26T03:49:08.857023Z",
     "iopub.status.idle": "2024-12-26T03:53:29.357815Z",
     "shell.execute_reply": "2024-12-26T03:53:29.356667Z",
     "shell.execute_reply.started": "2024-12-26T03:49:08.857331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ijson\n",
    "import csv\n",
    "\n",
    "# Path to the input JSON and output CSV files\n",
    "input_file = \"expanded.json\"\n",
    "output_file = \"output.csv\"\n",
    "\n",
    "# Function to extract keys\n",
    "def extract_keys(obj, prefix=\"\"):\n",
    "    keys = []\n",
    "    for key, value in obj.items():\n",
    "        full_key = f\"{prefix}.{key}\" if prefix else key\n",
    "        if isinstance(value, dict):\n",
    "            keys.extend(extract_keys(value, prefix=full_key))\n",
    "        else:\n",
    "            keys.append(full_key)\n",
    "    return keys\n",
    "\n",
    "# Open the JSON file for reading\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    # Open the CSV file for writing\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        # Parse the first item to extract headers\n",
    "        items = ijson.items(json_file, \"item\")\n",
    "        first_item = next(items, None)\n",
    "\n",
    "        if first_item:\n",
    "            # Get the headers (keys of the JSON object)\n",
    "            headers = extract_keys(first_item)\n",
    "\n",
    "            # Initialize CSV writer\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "\n",
    "            # Write the header row\n",
    "            writer.writeheader()\n",
    "\n",
    "            # Write the first item\n",
    "            writer.writerow(first_item)\n",
    "\n",
    "            # Write the rest of the items\n",
    "            for item in items:\n",
    "                writer.writerow(item)\n",
    "\n",
    "print(f\"JSON data has been written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T04:09:05.682868Z",
     "iopub.status.busy": "2024-12-26T04:09:05.682459Z",
     "iopub.status.idle": "2024-12-26T04:10:13.589464Z",
     "shell.execute_reply": "2024-12-26T04:10:13.588356Z",
     "shell.execute_reply.started": "2024-12-26T04:09:05.682832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"output.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T04:11:45.600865Z",
     "iopub.status.busy": "2024-12-26T04:11:45.600444Z",
     "iopub.status.idle": "2024-12-26T04:11:46.214544Z",
     "shell.execute_reply": "2024-12-26T04:11:46.210724Z",
     "shell.execute_reply.started": "2024-12-26T04:11:45.600833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Music\").getOrCreate()\n",
    "df = spark.read.csv(\"output.csv\", header=True)\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6375013,
     "sourceId": 10299602,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
