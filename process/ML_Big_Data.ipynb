{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zP8cn2YevVAU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in c:\\users\\pv\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\pv\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9VdqQBMOEcqS",
        "outputId": "fd4df52f-44c1-4be7-9d08-cf05a3cbd8dd"
      },
      "outputs": [
        {
          "ename": "Py4JError",
          "evalue": "An error occurred while calling None.org.apache.spark.sql.SparkSession. Trace:\npy4j.Py4JException: Constructor org.apache.spark.sql.SparkSession([class org.apache.spark.SparkContext, class java.util.HashMap]) does not exist\r\n\tat py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)\r\n\tat py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)\r\n\tat py4j.Gateway.invoke(Gateway.java:237)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Khởi tạo Spark session\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMusic Recommendation System\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Đọc dữ liệu từ CSV\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, inferSchema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\pv\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyspark\\sql\\session.py:500\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m     sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39mgetOrCreate(sparkConf)\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(session\u001b[38;5;241m.\u001b[39m_jvm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkSession$\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODULE$\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m     )\u001b[38;5;241m.\u001b[39mapplyModifiableSettings(session\u001b[38;5;241m.\u001b[39m_jsparkSession, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
            "File \u001b[1;32mc:\\Users\\pv\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyspark\\sql\\session.py:589\u001b[0m, in \u001b[0;36mSparkSession.__init__\u001b[1;34m(self, sparkContext, jsparkSession, options)\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkSession$\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODULE$\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mapplyModifiableSettings(\n\u001b[0;32m    586\u001b[0m             jsparkSession, options\n\u001b[0;32m    587\u001b[0m         )\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m         jsparkSession \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSparkSession\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkSession$\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODULE$\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mapplyModifiableSettings(\n\u001b[0;32m    592\u001b[0m         jsparkSession, options\n\u001b[0;32m    593\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\pv\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\py4j\\java_gateway.py:1587\u001b[0m, in \u001b[0;36mJavaClass.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1581\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1583\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1584\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1586\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1587\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fqn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1590\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\pv\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\py4j\\protocol.py:330\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n",
            "\u001b[1;31mPy4JError\u001b[0m: An error occurred while calling None.org.apache.spark.sql.SparkSession. Trace:\npy4j.Py4JException: Constructor org.apache.spark.sql.SparkSession([class org.apache.spark.SparkContext, class java.util.HashMap]) does not exist\r\n\tat py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)\r\n\tat py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)\r\n\tat py4j.Gateway.invoke(Gateway.java:237)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Khởi tạo Spark session\n",
        "spark = SparkSession.builder.appName(\"Music Recommendation System\").getOrCreate()\n",
        "\n",
        "# Đọc dữ liệu từ CSV\n",
        "df = spark.read.csv(\"output.csv\", header=True, sep=';', inferSchema=True)\n",
        "\n",
        "# Hiển thị DataFrame\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bF9jgLWLjA1Z"
      },
      "outputs": [],
      "source": [
        "#Lấy thông tin dòng số 50\n",
        "row = df.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1wdWP2n9jgwW",
        "outputId": "29042dbf-b18e-4177-818d-c1102602b26e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Row(Track ID='5zSKy9kDHd99HNPhiyB3bs', Track Name='El Valiente Cruz Vizcarra', Track Number='3', Duration (ms)=188368, Explicit='False', Album Name='Vino Maldito', Artists=\"['Luis y Julian']\", Genres=\"['norteno']\", Available Markets='AR, AU, AT, BE, BO, BR, BG, CA, CL, CO, CR, CY, CZ, DK, DO, DE, EC, EE, SV, FI, FR, GR, GT, HN, HK, HU, IS, IE, IT, LV, LT, LU, MY, MT, MX, NL, NZ, NI, NO, PA, PY, PE, PH, PL, PT, SG, SK, ES, SE, CH, TW, TR, UY, US, GB, AD, LI, MC, ID, JP, TH, VN, RO, IL, ZA, SA, AE, BH, QA, OM, KW, EG, MA, DZ, TN, LB, JO, PS, IN, BY, KZ, MD, UA, AL, BA, HR, ME, MK, RS, SI, KR, BD, PK, LK, GH, KE, NG, TZ, UG, AG, AM, BS, BB, BZ, BT, BW, BF, CV, CW, DM, FJ, GM, GE, GD, GW, GY, HT, JM, KI, LS, LR, MW, MV, ML, MH, FM, NA, NR, NE, PW, PG, PR, WS, SM, ST, SN, SC, SL, SB, KN, LC, VC, SR, TL, TO, TT, TV, VU, AZ, BN, BI, KH, CM, TD, KM, GQ, SZ, GA, GN, KG, LA, MO, MR, MN, NP, RW, TG, UZ, ZW, BJ, MG, MU, MZ, AO, CI, DJ, ZM, CD, CG, IQ, LY, TJ, VE, ET, XK', Popularity='0', Acousticness=0.42, Energy=0.405, Instrumentalness=2.03e-05, Liveness=0.08990000000000001, Loudness=-13.973, Mode=1.0, Speechiness=0.0925, Tempo=94.417, Time Signature=4.0, Valence=0.859)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "row[2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VnmWrOgPhljY",
        "outputId": "33bca613-f8b8-488e-ac2b-69d0107de46b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+----------+--------------------+------------------+-----------------+----------+------------------------+--------------------+--------------------+--------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+\n",
            "|summary|            Track ID|Track Name|        Track Number|     Duration (ms)|         Explicit|Album Name|                 Artists|              Genres|   Available Markets|          Popularity|      Acousticness|             Energy|   Instrumentalness|           Liveness|           Loudness|               Mode|        Speechiness|             Tempo|    Time Signature|            Valence|\n",
            "+-------+--------------------+----------+--------------------+------------------+-----------------+----------+------------------------+--------------------+--------------------+--------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+\n",
            "|  count|              294952|    294951|              294952|            294952|           294952|    294952|                  294952|              294952|              288678|              294952|            294952|             294952|             294952|             294952|             294952|             294952|             294952|            294952|            294952|             294952|\n",
            "|   mean|                NULL|  Infinity|   9.766741143324055|214026.76439556267|         233041.0|  Infinity|                    NULL|                NULL|                NULL|  13.198727228959779|0.4678557821084363| 0.5021128530543906|0.24824775723842923| 0.2203686019249555|-12.007348599094236| 0.6832362113157394|0.10007094917139094|116.36607978993229| 3.825282930781958|0.46083682717527014|\n",
            "| stddev|                NULL|       NaN|    8.44309334799752|119103.77307611484|96275.93321801664|       NaN|                    NULL|                NULL|                NULL|  14.216707287562848|0.3614534706349875|0.28020661780882694| 0.3783800260064697|0.20789717496292268|  7.707549106936389|0.47473497050581115|0.13128872749477805| 31.94264869177799|0.7254474408174307| 0.2898810752878277|\n",
            "|    min|0007AYhg2UQbEm88m...|         !| Indietro, indiet...|                 0|           275373|         !|    \"[\"\"'In The Heigh...|\"[\"\"australian ch...|AD, AE, AG, AM, A...|                   0|               0.0|                0.0|                0.0|                0.0|              -60.0|            -24.803|                0.0|               0.0|               0.0|                0.0|\n",
            "|    max|7zzmpC8CdWK4pY2se...|        𤷪|                   9|           5192359|             True|행복하세요|['高田龍一', '高田龍一']|                  []|['italian romanti...|AR, AU, AT, BE, B...|              14.0|                1.0|                1.0|                1.0|              2.009|                1.0|                1.0|             244.2|           138.532|                5.0|\n",
            "+-------+--------------------+----------+--------------------+------------------+-----------------+----------+------------------------+--------------------+--------------------+--------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Thống kê mô tả cho các cột số\n",
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3DS6rVclNbO"
      },
      "source": [
        "#ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnbcJqNflOXk",
        "outputId": "2f6cf373-d2f9-4695-88b4-a0920139e045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|Popularity|\n",
            "+----------+\n",
            "|         0|\n",
            "+----------+\n",
            "\n",
            "+--------------------+--------------------+--------------------+----------+----------+\n",
            "|          Track Name|             Artists|              Genres|Popularity|prediction|\n",
            "+--------------------+--------------------+--------------------+----------+----------+\n",
            "|Eu, Você, O Mar e...|    ['Luan Santana']|['sertanejo unive...|        65|        12|\n",
            "|        Getting Away|  ['KR$NA', 'KR$NA']|['desi hip hop', ...|        14|        16|\n",
            "|Suspension (Acous...|          ['Lights']|['indie poptimism...|        17|        14|\n",
            "|AOGG (feat. Tay K...|['Kenny Muney', '...| ['memphis hip hop']|        24|        16|\n",
            "|             Disgust|  ['KMFDM', 'KMFDM']|['industrial meta...|        13|        11|\n",
            "|     Paradise Is You|         ['La Roux']|['electropop', 'a...|        26|        20|\n",
            "| Compay Póngase Duro|  ['Lalo Rodriguez']|['salsa', 'salsa ...|         9|        14|\n",
            "|6 Épigraphes anti...|['Claude Debussy'...|['impressionism',...|         0|         2|\n",
            "|Nena Mori Taras l...|['Javed Bashir', ...|['classic pakista...|         5|        13|\n",
            "|        By Your Side|       ['Lifehouse']|['post-grunge', '...|        26|        16|\n",
            "|Intro (A butterfl...|      ['Loossemble']|   ['5th gen k-pop']|        32|        13|\n",
            "|   I Really Love You|['Keith Sweat', '...|['r&b', 'new jack...|        14|        14|\n",
            "|fly high!! (haiky...|  ['kohto', 'kohto']|                  []|         9|         5|\n",
            "|     Unconditionally|['Katy Perry', 'K...|             ['pop']|        75|        18|\n",
            "|Target Is Getting...|['Kevin Kiner', '...|      ['soundtrack']|         8|        13|\n",
            "|         Lucy Locket|['The Little Suns...|\"[\"\"children's mu...|        10|        10|\n",
            "|            Looptown|['Junior Mance', ...|['stride', 'hard ...|         0|         8|\n",
            "|    Disillusion Town|['The Knack', 'Th...|['new wave pop', ...|         1|        18|\n",
            "|El Corrido del Si...|['La Original Ban...|['banda', 'norten...|        36|        11|\n",
            "|Backwards - Live ...|['Kings Kaleidosc...|['christian uplif...|        10|        15|\n",
            "+--------------------+--------------------+--------------------+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Mean Absolute Error (MAE): 10.574870458623435\n",
            "Mean Squared Error (MSE): 178.08776262923723\n",
            "R-squared: 0.11397259185570863\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression  # Linear Regression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Bước 1: Khởi tạo Spark session\n",
        "spark = SparkSession.builder.appName(\"Popularity\").getOrCreate()\n",
        "\n",
        "# Bước 2: Tạo DataFrame mẫu\n",
        "df = spark.read.csv(\"album_tracks_train_full.csv\", header=True, sep=';', inferSchema=True)\n",
        "\n",
        "# Chuyển đổi cột 'Popularity' thành kiểu IntegerType\n",
        "df = df.withColumn(\"Popularity\", df[\"Popularity\"].cast(IntegerType()))\n",
        "\n",
        "# Kiểm tra và xử lý giá trị null hoặc NaN trong cột 'Popularity'\n",
        "df.select([count(when(isnan(c), c)).alias(c) for c in [\"Popularity\"]]).show()\n",
        "\n",
        "# Loại bỏ các hàng có giá trị null hoặc NaN trong cột 'Popularity'\n",
        "df = df.na.drop(subset=[\"Popularity\"])\n",
        "\n",
        "# Bước 3: Tiền xử lý dữ liệu\n",
        "indexer_artists = StringIndexer(inputCol=\"Artists\", outputCol=\"Artists_Index\", handleInvalid=\"keep\")\n",
        "indexer_genres = StringIndexer(inputCol=\"Genres\", outputCol=\"Genres_Index\", handleInvalid=\"keep\")\n",
        "\n",
        "# Tạo VectorAssembler để kết hợp các đặc trưng\n",
        "assembler = VectorAssembler(inputCols=[\"Artists_Index\", \"Genres_Index\", \"Acousticness\", \"Energy\", \"Instrumentalness\", \"Liveness\", \"Loudness\", \"Mode\", \"Speechiness\", \"Tempo\", \"Valence\"], outputCol=\"features\")\n",
        "\n",
        "# Bước 4: Xây dựng mô hình sử dụng LinearRegression\n",
        "linear_reg = LinearRegression(featuresCol=\"features\", labelCol=\"Popularity\")\n",
        "\n",
        "# Tạo Pipeline\n",
        "pipeline = Pipeline(stages=[indexer_artists, indexer_genres, assembler, linear_reg])\n",
        "\n",
        "# Bước 5: Chia dữ liệu\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "model = pipeline.fit(train_df)\n",
        "\n",
        "# Dự đoán\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "# Bước 6: Tính toán các metric lỗi\n",
        "evaluator = RegressionEvaluator(labelCol=\"Popularity\", predictionCol=\"prediction\", metricName=\"mae\")\n",
        "mae = evaluator.evaluate(predictions)\n",
        "\n",
        "evaluator.setMetricName(\"mse\")\n",
        "mse = evaluator.evaluate(predictions)\n",
        "\n",
        "evaluator.setMetricName(\"r2\")\n",
        "r2 = evaluator.evaluate(predictions)\n",
        "\n",
        "# Hiển thị kết quả\n",
        "predictions = predictions.withColumn(\"prediction\", col(\"prediction\").cast(IntegerType()))\n",
        "predictions.select(\"Track Name\", \"Artists\", \"Genres\", \"Popularity\", \"prediction\").show()\n",
        "\n",
        "# In các metric lỗi\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3OCN6Bjffz8O",
        "outputId": "b2d39f01-ac8c-4b5b-e87b-ea2fa74930a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|Popularity|\n",
            "+----------+\n",
            "|         0|\n",
            "+----------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 3, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 6, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.01, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.001, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 10, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.3 on 1 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'reg:squarederror', 'reg_lambda': 1, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+----------+------------------+\n",
            "|          Track Name|             Artists|              Genres|Popularity|        prediction|\n",
            "+--------------------+--------------------+--------------------+----------+------------------+\n",
            "|Eu, Você, O Mar e...|    ['Luan Santana']|['sertanejo unive...|        65|19.651870727539062|\n",
            "|        Getting Away|  ['KR$NA', 'KR$NA']|['desi hip hop', ...|        14|21.586992263793945|\n",
            "|Suspension (Acous...|          ['Lights']|['indie poptimism...|        17|16.666772842407227|\n",
            "|AOGG (feat. Tay K...|['Kenny Muney', '...| ['memphis hip hop']|        24| 21.61313247680664|\n",
            "|             Disgust|  ['KMFDM', 'KMFDM']|['industrial meta...|        13| 12.55388355255127|\n",
            "|     Paradise Is You|         ['La Roux']|['electropop', 'a...|        26|26.241558074951172|\n",
            "| Compay Póngase Duro|  ['Lalo Rodriguez']|['salsa', 'salsa ...|         9| 14.90137767791748|\n",
            "|6 Épigraphes anti...|['Claude Debussy'...|['impressionism',...|         0| 6.657959461212158|\n",
            "|Nena Mori Taras l...|['Javed Bashir', ...|['classic pakista...|         5|12.420166969299316|\n",
            "|        By Your Side|       ['Lifehouse']|['post-grunge', '...|        26|23.637889862060547|\n",
            "|Intro (A butterfl...|      ['Loossemble']|   ['5th gen k-pop']|        32|20.257415771484375|\n",
            "|   I Really Love You|['Keith Sweat', '...|['r&b', 'new jack...|        14|13.312310218811035|\n",
            "|fly high!! (haiky...|  ['kohto', 'kohto']|                  []|         9|13.850394248962402|\n",
            "|     Unconditionally|['Katy Perry', 'K...|             ['pop']|        75| 46.43045425415039|\n",
            "|Target Is Getting...|['Kevin Kiner', '...|      ['soundtrack']|         8| 7.991644382476807|\n",
            "|         Lucy Locket|['The Little Suns...|\"[\"\"children's mu...|        10|10.775242805480957|\n",
            "|            Looptown|['Junior Mance', ...|['stride', 'hard ...|         0| 4.692934036254883|\n",
            "|    Disillusion Town|['The Knack', 'Th...|['new wave pop', ...|         1|15.209539413452148|\n",
            "|El Corrido del Si...|['La Original Ban...|['banda', 'norten...|        36| 16.81875991821289|\n",
            "|Backwards - Live ...|['Kings Kaleidosc...|['christian uplif...|        10| 16.58184051513672|\n",
            "+--------------------+--------------------+--------------------+----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Mean Absolute Error (MAE): 10.687781997909447\n",
            "Mean Squared Error (MSE): 114.22868403483726\n",
            "R-squared: 0.43168613408979883\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from xgboost.spark import SparkXGBRegressor  # Nhập XGBoostRegressor\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import isnan, when, count\n",
        "\n",
        "# Bước 1: Khởi tạo Spark session\n",
        "spark = SparkSession.builder.appName(\"Popularity\").getOrCreate()\n",
        "\n",
        "# Bước 2: Tạo DataFrame từ file CSV\n",
        "df = spark.read.csv(\"album_tracks_train_full.csv\", header=True, sep=';', inferSchema=True)\n",
        "\n",
        "# Bước 3: Chuyển đổi cột 'Popularity' thành kiểu IntegerType\n",
        "df = df.withColumn(\"Popularity\", df[\"Popularity\"].cast(IntegerType()))\n",
        "\n",
        "# Bước 4: Kiểm tra và xử lý giá trị null hoặc NaN trong cột 'Popularity'\n",
        "df.select([count(when(isnan(c), c)).alias(c) for c in [\"Popularity\"]]).show()\n",
        "df = df.na.drop(subset=[\"Popularity\"])  # Loại bỏ các hàng có giá trị null hoặc NaN\n",
        "\n",
        "# Bước 5: Tiền xử lý dữ liệu\n",
        "# Chuyển đổi các cột danh mục thành số\n",
        "indexer_artists = StringIndexer(inputCol=\"Artists\", outputCol=\"Artists_Index\", handleInvalid=\"keep\")\n",
        "indexer_genres = StringIndexer(inputCol=\"Genres\", outputCol=\"Genres_Index\", handleInvalid=\"keep\")\n",
        "\n",
        "# Tạo VectorAssembler để kết hợp các đặc trưng\n",
        "assembler = VectorAssembler(inputCols=[\"Artists_Index\", \"Genres_Index\", \"Acousticness\", \"Energy\",\n",
        "                                        \"Instrumentalness\", \"Liveness\", \"Loudness\",\n",
        "                                        \"Mode\", \"Speechiness\", \"Tempo\", \"Time Signature\", \"Valence\"],\n",
        "                            outputCol=\"features\")\n",
        "\n",
        "# Bước 6: Chuẩn hóa các đặc trưng số\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
        "\n",
        "# Bước 7: Sử dụng XGBoostRegressor\n",
        "xgboost_reg = SparkXGBRegressor(features_col=\"scaled_features\", label_col=\"Popularity\")\n",
        "\n",
        "# Bước 8: Tạo Pipeline bao gồm tất cả các bước\n",
        "pipeline = Pipeline(stages=[indexer_artists, indexer_genres, assembler, scaler, xgboost_reg])\n",
        "\n",
        "# Bước 9: Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Bước 10: Tuning hyperparameters với CrossValidator\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(xgboost_reg.max_depth, [3, 6, 10]) \\\n",
        "    .addGrid(xgboost_reg.learning_rate, [0.1, 0.01, 0.001]) \\\n",
        "    .addGrid(xgboost_reg.reg_lambda, [1, 10]) \\\n",
        "    .build()\n",
        "\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=RegressionEvaluator(labelCol=\"Popularity\", predictionCol=\"prediction\", metricName=\"mae\"),\n",
        "                          numFolds=3)  # 3-fold CrossValidation\n",
        "\n",
        "# Bước 11: Huấn luyện mô hình\n",
        "cv_model = crossval.fit(train_df)\n",
        "\n",
        "# Bước 12: Dự đoán trên tập kiểm tra\n",
        "predictions = cv_model.transform(test_df)\n",
        "\n",
        "# Bước 13: Tính toán các metric lỗi\n",
        "evaluator = RegressionEvaluator(labelCol=\"Popularity\", predictionCol=\"prediction\")\n",
        "mae = evaluator.evaluate(predictions)\n",
        "mse = evaluator.setMetricName(\"mse\").evaluate(predictions)\n",
        "r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
        "\n",
        "# Bước 14: Hiển thị kết quả dự đoán\n",
        "predictions.select(\"Track Name\", \"Artists\", \"Genres\", \"Popularity\", \"prediction\").show()\n",
        "\n",
        "# Bước 15: In các metric lỗi\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Dừng Spark session\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
